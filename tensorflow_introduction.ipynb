{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf                                                                        \n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist                                                   # starter dataset from keras\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()           # split into training and testing\n",
    "\n",
    "train_images.shape\n",
    "train_images[0,23,22]                                                                          # 0th image, 24th row, 23rd collumn\n",
    "train_labels[:10]                                                                              # labels = classifications        # 0-9th images\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def heatmap_visualization(indices):\n",
    "    plt.figure()                                                                               \n",
    "    plt.imshow(test_images[indices])                                                          # train_images // test_images\n",
    "    plt.colorbar()\n",
    "    plt.grid(False)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 649us/step - loss: 0.4982 - accuracy: 0.8250\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 649us/step - loss: 0.3788 - accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 1s 655us/step - loss: 0.3410 - accuracy: 0.8759\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.3165 - accuracy: 0.8840\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 648us/step - loss: 0.2974 - accuracy: 0.8897\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.2816 - accuracy: 0.8961\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 663us/step - loss: 0.2699 - accuracy: 0.9001\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 678us/step - loss: 0.2573 - accuracy: 0.9042\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 647us/step - loss: 0.2488 - accuracy: 0.9074\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 648us/step - loss: 0.2395 - accuracy: 0.9103\n",
      "Test accuracy: 0.8787999749183655\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),                                                # flattens all 28x28=784 into input layer\n",
    "    keras.layers.Dense(128, activation='relu'),                                                # dense hidden layer means all previous connected to all current neurons in network\n",
    "    keras.layers.Dense(10, activation='softmax')                                               # a probability layer is output layer, all values (0 -> 1) and (probability distribution) and (=1)\n",
    "                         ])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',                                                                # algorithm that performs gradient descent\n",
    "              loss='sparse_categorical_crossentropy',                                          # loss\n",
    "              metrics=['accuracy'])                                                            # output of network\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)                                               # passing data, establishing epochs, fitting=training \n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1)                     # testing model\n",
    "\n",
    "print('Test accuracy:', test_acc)                                                              # accuracy is useful to evaluate hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)                                                       # prediction outputs a probability distribution for every image in array\n",
    "\n",
    "print(predictions[0])                                                                          # probability distribution of 0th image being classified into each of the 10 classes\n",
    "print(class_names[np.argmax(predictions[22])])                                                  # returns class[index] of highest value in array  == classification 9 is ankle boot\n",
    "visualization = heatmap_visualization(22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
